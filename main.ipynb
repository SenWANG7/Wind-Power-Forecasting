{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:00:14.064128Z",
     "iopub.status.busy": "2024-11-30T04:00:14.063426Z",
     "iopub.status.idle": "2024-11-30T04:00:14.070510Z",
     "shell.execute_reply": "2024-11-30T04:00:14.069735Z",
     "shell.execute_reply.started": "2024-11-30T04:00:14.064089Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import paddle\n",
    "print(paddle.__version__)\n",
    "import paddlets\n",
    "print(paddlets.__version__)\n",
    "\n",
    "from paddlets.utils import backtest\n",
    "from paddlets import TSDataset, TimeSeries\n",
    "from paddlets.xai.post_hoc.shap_explainer import ShapExplainer\n",
    "from paddlets.datasets.repository import get_dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:04:55.253758Z",
     "iopub.status.busy": "2024-11-30T04:04:55.252616Z",
     "iopub.status.idle": "2024-11-30T04:04:55.386422Z",
     "shell.execute_reply": "2024-11-30T04:04:55.385211Z",
     "shell.execute_reply.started": "2024-11-30T04:04:55.253704Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#加载数据 再训练\n",
    "data = pd.read_csv('/home/Zone9-power.csv')\n",
    "\n",
    "# 将时间戳列转换为日期时间格式\n",
    "data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'])\n",
    "\n",
    "# 将数据按照时间顺序排序\n",
    "data.sort_values('TIMESTAMP', inplace=True)\n",
    "\n",
    "# 划分数据集\n",
    "train_dataset = data[data['TIMESTAMP'].dt.year == 2012]\n",
    "val_dataset = data[(data['TIMESTAMP'].dt.year == 2013) & (data['TIMESTAMP'].dt.month == 1)]\n",
    "test_dataset = train_dataset\n",
    "\n",
    "# 在这里定义模型的out_chunk_len\n",
    "model_out_chunk_len = 4\n",
    "\n",
    "train_dataset_target = train_dataset[:-model_out_chunk_len]\n",
    "val_dataset_target = val_dataset[:-model_out_chunk_len]\n",
    "test_dataset_target = test_dataset[:-model_out_chunk_len]\n",
    "\n",
    "\n",
    "# 检查数据集的大小\n",
    "print(\"训练集大小:\", len(train_dataset))\n",
    "print(\"验证集大小:\", len(val_dataset))\n",
    "print(\"测试集大小:\", len(test_dataset))\n",
    "\n",
    "# 打印前五行数据\n",
    "print(train_dataset.head())\n",
    "print(val_dataset.head())\n",
    "print(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "data = pd.read_csv('/home/Zone1-power.csv')\n",
    "\n",
    "# 将时间戳列转换为日期时间格式\n",
    "data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'])\n",
    "\n",
    "# 将数据按照时间顺序排序\n",
    "data.sort_values('TIMESTAMP', inplace=True)\n",
    "\n",
    "# 划分数据集\n",
    "train_dataset = data[data['TIMESTAMP'].dt.year == 2012]\n",
    "val_dataset = data[(data['TIMESTAMP'].dt.year == 2013) & (data['TIMESTAMP'].dt.month == 1)]\n",
    "test_dataset = data[(data['TIMESTAMP'].dt.year == 2013) & (data['TIMESTAMP'].dt.month == 2)]\n",
    "\n",
    "# 检查数据集的大小\n",
    "print(\"训练集大小:\", len(train_dataset))\n",
    "print(\"验证集大小:\", len(val_dataset))\n",
    "print(\"测试集大小:\", len(test_dataset))\n",
    "\n",
    "# 打印前五行数据\n",
    "print(train_dataset.head())\n",
    "print(val_dataset.head())\n",
    "print(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:04:58.485502Z",
     "iopub.status.busy": "2024-11-30T04:04:58.484844Z",
     "iopub.status.idle": "2024-11-30T04:04:59.347189Z",
     "shell.execute_reply": "2024-11-30T04:04:59.346339Z",
     "shell.execute_reply.started": "2024-11-30T04:04:58.485451Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#数据转换\n",
    "from paddlets import TSDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_cov_dataset1 = TSDataset.load_from_dataframe(\n",
    "    train_dataset,\n",
    "    time_col='TIMESTAMP',\n",
    "    target_cols='TARGETVAR',\n",
    "    freq='1h'\n",
    "    )\n",
    "\n",
    "target_cov_dataset2 = TSDataset.load_from_dataframe(\n",
    "    val_dataset,\n",
    "    time_col='TIMESTAMP',\n",
    "    target_cols='TARGETVAR',\n",
    "    freq='1h'\n",
    "    )\n",
    "\n",
    "target_cov_dataset3 = TSDataset.load_from_dataframe(\n",
    "    test_dataset,\n",
    "    time_col='TIMESTAMP',\n",
    "    target_cols='TARGETVAR',\n",
    "    freq='1h'\n",
    "    )\n",
    "\n",
    "train_dataset = target_cov_dataset1\n",
    "val_dataset = target_cov_dataset2\n",
    "test_dataset = target_cov_dataset3#分割数据集\n",
    "\n",
    "train_dataset.plot(add_data=[val_dataset,test_dataset], labels=['Val', 'Test'])\n",
    "plt.savefig('fig1.svg',format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:05:01.522395Z",
     "iopub.status.busy": "2024-11-30T04:05:01.521741Z",
     "iopub.status.idle": "2024-11-30T04:07:59.546161Z",
     "shell.execute_reply": "2024-11-30T04:07:59.545291Z",
     "shell.execute_reply.started": "2024-11-30T04:05:01.522351Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from informer import *\n",
    "InF = InformerModel(\n",
    "    in_chunk_len = 24*3,\n",
    "    out_chunk_len = 4,\n",
    "    max_epochs = 50,\n",
    "    d_model = 64,\n",
    "    nhead = 8,\n",
    "    start_token_len = 6,\n",
    "    ffn_channels = 1024,\n",
    "    num_encoder_layers = 2,\n",
    "    num_decoder_layers = 1,\n",
    "    activation = \"relu\",\n",
    "    verbose = 1,\n",
    "    patience = 4\n",
    "    )\n",
    "InF.fit(train_dataset, val_dataset)\n",
    "subset_test_pred_dataset = InF.predict(test_dataset)#模型预测\n",
    "subset_test_dataset, _ = test_dataset.split(len(subset_test_pred_dataset.target))#截取某天进行预测\n",
    "subset_test_dataset.plot(add_data=subset_test_pred_dataset, labels=['Pred'])\n",
    "from paddlets.utils import backtest\n",
    "score, preds_data= backtest(\n",
    "    data=test_dataset,\n",
    "    model=InF,\n",
    "    return_predicts = True)\n",
    "print(f\"mae: {score}\")\n",
    "test_dataset.plot(add_data=preds_data,labels=\"backtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:08:52.617743Z",
     "iopub.status.busy": "2024-11-30T04:08:52.617118Z",
     "iopub.status.idle": "2024-11-30T04:08:52.756197Z",
     "shell.execute_reply": "2024-11-30T04:08:52.754852Z",
     "shell.execute_reply.started": "2024-11-30T04:08:52.617705Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = preds_data.to_dataframe()\n",
    "pred.to_csv(\"ts1111.csv\")\n",
    "true = test_dataset.to_dataframe()\n",
    "true.to_csv(\"ts2222.csv\")\n",
    "\n",
    "pred=pd.read_csv('ts1111.csv')\n",
    "pred=pred.rename(columns={pred.columns[0]: 'TIMESTAMP',pred.columns[1]: 'pred'})\n",
    "true=pd.read_csv('ts2222.csv')\n",
    "df_merged = pd.merge(pred, true, on=\"TIMESTAMP\", how=\"inner\")\n",
    "df_merged.to_csv(\"trans9.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
